{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "keras_lm_pos_seq2seqLM.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "iFdRuNU0T5he",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8d207efa-0f21-43e0-9dce-e9888a018535",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1528812282143,
          "user_tz": -330,
          "elapsed": 2308,
          "user": {
            "displayName": "Murali Manohar",
            "photoUrl": "//lh4.googleusercontent.com/-FtcF8oOHMfk/AAAAAAAAAAI/AAAAAAAACRQ/64DBd_-9-UY/s50-c-k-no/photo.jpg",
            "userId": "117676050852919577098"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "colab_lm_pos  datalab\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "z7Utjm8mUAB1",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3d726f34-d712-4ec1-a471-2d596f3a74e4",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1528812296559,
          "user_tz": -330,
          "elapsed": 2453,
          "user": {
            "displayName": "Murali Manohar",
            "photoUrl": "//lh4.googleusercontent.com/-FtcF8oOHMfk/AAAAAAAAAAI/AAAAAAAACRQ/64DBd_-9-UY/s50-c-k-no/photo.jpg",
            "userId": "117676050852919577098"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.layers import Input, Dense\n",
        "from keras.models import Model\n",
        "from keras.utils import plot_model\n",
        "from numpy import array\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import TimeDistributed,Activation\n",
        "\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import SimpleRNN\n",
        "from keras.layers.convolutional import Conv1D\n",
        "from keras.layers.convolutional import MaxPooling1D\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.layers import Flatten\n",
        "from keras.preprocessing import sequence\n",
        "from keras.utils import to_categorical\n",
        "from keras.callbacks import Callback\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "# from keras import backend as K\n",
        "# K.tensorflow_backend._get_available_gpus()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "y9LpKXYXUE-8",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9Mbhgo0RUSpj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Pre-process the data"
      ]
    },
    {
      "metadata": {
        "id": "NOTP088MUGf0",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from pickle import dump\n",
        "from pickle import load\n",
        "import pickle\n",
        "with open(\"colab_lm_pos/telugu_pos_tag_data.pickle\",\"rb\") as fhnd:\n",
        "    total_data=pickle.load(fhnd)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YDZG9LguUVFw",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "word_to_idx=load(open(\"colab_lm_pos/word_to_idx.pickle\",\"rb\"))\n",
        "\n",
        "pos_map=load(open(\"colab_lm_pos/pos_map.pickle\",\"rb\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oneUjH2AUK0C",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Converge all sentences into one big list and their pos tags into another simultaneous list\n",
        "\n",
        "# train_data = [1,3,4,2,789,........, 103589]"
      ]
    },
    {
      "metadata": {
        "id": "u6boK0oZULf0",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "sentences=[]\n",
        "labels=[]\n",
        "\n",
        "train_data=[]\n",
        "label_data=[]\n",
        "\n",
        "target_task_indx_start=0\n",
        "target_task_indx_end=0\n",
        "\n",
        "length = 5\n",
        "\n",
        "\n",
        "for m,(sent,tag) in enumerate(total_data):\n",
        "    sentences+=sent\n",
        "    labels+=tag\n",
        "    for wrdi in sent:\n",
        "        res=word_to_idx[wrdi]\n",
        "        train_data.append(res)\n",
        "    \n",
        "    for tagi in tag:\n",
        "        res=pos_map[tagi]\n",
        "        label_data.append(res)\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Cx2vVf6EUnt2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "# For fit generator multiple outputs\n",
        "https://github.com/keras-team/keras/blob/master/keras/engine/training.py#L1128"
      ]
    },
    {
      "metadata": {
        "id": "hzhGr2dFUNto",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QNQ9xYa5UqqR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Example\n",
        "        \n",
        "def generate_arrays_from_file(path):\n",
        "\n",
        "    while True:\n",
        "        with open(path) as f:\n",
        "            for line in f:\n",
        "                # create numpy arrays of input data\n",
        "                # and labels, from each line in the file\n",
        "                x1, x2, y = process_line(line)\n",
        "                yield ({'input_1': x1, 'input_2': x2}, {'output': y})\n",
        "\n",
        "model.fit_generator(generate_arrays_from_file('/my_file.txt'),steps_per_epoch=10000, epochs=10)\n",
        "   "
      ]
    },
    {
      "metadata": {
        "id": "tdE9fheAUs8_",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tMcj5o84U1oP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Generator class"
      ]
    },
    {
      "metadata": {
        "id": "xcNhKGo0U2Rs",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "class KerasBatchGenerator(object):\n",
        "\n",
        "    def __init__(self, data, labeldata,num_steps, batch_size, vocabulary, pos_tag_size,skip_step):\n",
        "        self.data = data\n",
        "        self.num_steps = num_steps\n",
        "        self.batch_size = batch_size\n",
        "        self.vocabulary = vocabulary\n",
        "        self.labeldata=labeldata\n",
        "        self.pos_tag_size=pos_tag_size\n",
        "        # this will track the progress of the batches sequentially through the\n",
        "        # data set - once the data reaches the end of the data set it will reset\n",
        "        # back to zero\n",
        "        self.current_idx = 0\n",
        "        # skip_step is the number of words which will be skipped before the next\n",
        "        # batch is skimmed from the data set\n",
        "        self.skip_step = skip_step\n",
        "\n",
        "    def generate(self,phase=None):\n",
        "        x = np.zeros((self.batch_size, self.num_steps))\n",
        "        \n",
        "        if phase==None:\n",
        "            print(\"Phase not mentioned!!!!!\")\n",
        "            return \n",
        "        \n",
        "        if phase==1:\n",
        "            y = np.zeros((self.batch_size, self.num_steps, self.vocabulary))\n",
        "        \n",
        "        if phase==2:\n",
        "            y = np.zeros((self.batch_size,self.num_steps,self.vocabulary))\n",
        "            phase2_y = np.zeros((self.batch_size, self.num_steps, self.pos_tag_size))\n",
        "        \n",
        "\n",
        "        \n",
        "        while True:\n",
        "            for i in range(self.batch_size):\n",
        "                if self.current_idx + self.num_steps >= len(self.data):\n",
        "                    # reset the index back to the start of the data set\n",
        "                    self.current_idx = 0\n",
        "                \n",
        "                x[i, :] = self.data[self.current_idx:self.current_idx + self.num_steps]\n",
        "\n",
        "                \n",
        "                if phase==1:\n",
        "                    \n",
        "                    temp_y = self.data[self.current_idx + 1:self.current_idx + self.num_steps + 1]\n",
        "#                     temp_y = self.data[self.current_idx+self.num_steps]\n",
        "                    # convert all of temp_y into a one hot representation\n",
        "                    y[i, :,:] = to_categorical(temp_y, num_classes=self.vocabulary)\n",
        "#                     self.current_idx += self.skip_step                    \n",
        "                    yield x, y\n",
        "                \n",
        "                \n",
        "                elif phase==2:\n",
        "\n",
        "                    temp_y = self.data[self.current_idx + 1:self.current_idx + self.num_steps + 1]\n",
        "#                     temp_y = self.data[self.current_idx+self.num_steps]\n",
        "                    # convert all of temp_y into a one hot representation\n",
        "                    y[i, :,:] = to_categorical(temp_y, num_classes=self.vocabulary)\n",
        "    \n",
        "                    temp_phase2_y = self.labeldata[self.current_idx:self.current_idx + self.num_steps]\n",
        "                    # convert all of temp_y into a one hot representation\n",
        "                    phase2_y[i, :, :] = to_categorical(temp_phase2_y, num_classes=self.pos_tag_size)\n",
        "                    yield ({'main_input': x}, {'LM_output': y,'POS_output':phase2_y})\n",
        "                self.current_idx += self.skip_step                    \n",
        "\n",
        "\n",
        "    \n",
        "            \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_SLkUMwaU6co",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "vocabulary=len(word_to_idx)\n",
        "pos_tag_size=len(pos_map)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gx5K_6NdU9g9",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "num_steps = 5\n",
        "batch_size = 128\n",
        "phase1_train_data_generator = KerasBatchGenerator(train_data,label_data, num_steps, batch_size, vocabulary,pos_tag_size,skip_step=1)\n",
        "phase2_train_data_generator = KerasBatchGenerator(train_data,label_data, num_steps, batch_size, vocabulary,pos_tag_size,skip_step=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fj5n7fLtU_Ox",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iC-JRMmLVCka",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# ***** Actual required Design for the model *******"
      ]
    },
    {
      "metadata": {
        "id": "O4nV09UxVDHE",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "432f1d4c-3d8d-4e08-c3f1-04ea29b9689f",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1528813753101,
          "user_tz": -330,
          "elapsed": 970,
          "user": {
            "displayName": "Murali Manohar",
            "photoUrl": "//lh4.googleusercontent.com/-FtcF8oOHMfk/AAAAAAAAAAI/AAAAAAAACRQ/64DBd_-9-UY/s50-c-k-no/photo.jpg",
            "userId": "117676050852919577098"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "max_input_length=num_steps\n",
        "embedding_dim=300\n",
        "vocab_size=vocabulary\n",
        "hidden_dim=200\n",
        "\n",
        "\n",
        "main_input = Input(shape=(max_input_length,), dtype='float32', name='main_input')\n",
        "\n",
        "# This embedding layer will encode the input sequence\n",
        "# into a sequence of dense 512-dimensional vectors.\n",
        "\n",
        "x = Embedding(output_dim=embedding_dim, input_dim=vocab_size, input_length=max_input_length,name=\"embedding\")(main_input)\n",
        "\n",
        "# A LSTM will transform the vector sequence into a single vector,\n",
        "# containing information about the entire sequence\n",
        "lstm_out,state_h, state_c = LSTM(hidden_dim,return_sequences=True, return_state=True,name=\"LSTM\")(x)\n",
        "\n",
        "print(lstm_out.shape)\n",
        "\n",
        "auxiliary_output = TimeDistributed(Dense(pos_tag_size, activation='sigmoid'), name='POS_output')(lstm_out)\n",
        "\n",
        "# auxiliary_output = Dense(1, activation='sigmoid', name='aux_output')(lstm_out)\n",
        "\n",
        "# auxiliary_input = Input(shape=(5,), name='aux_input')\n",
        "# x = keras.layers.concatenate([lstm_out, auxiliary_input])\n",
        "\n",
        "\n",
        "# We stack a deep densely-connected network on top\n",
        "\n",
        "# x = Dense(400, activation='relu',name=\"dense\")(state_h)\n",
        "\n",
        "# x = Dense(64, activation='relu')(x)\n",
        "# x = Dense(64, activation='relu')(x)\n",
        "\n",
        "# And finally we add the main logistic regression layer\n",
        "\n",
        "# main_output = Dense(vocab_size, activation='softmax', name='LM_output')(state_h)\n",
        "\n",
        "main_output = TimeDistributed(Dense(vocabulary, activation='sigmoid'), name='LM_output')(lstm_out)\n",
        "\n",
        "phase1_model= Model(inputs=[main_input], outputs=[main_output])\n",
        "phase2_model = Model(inputs=[main_input], outputs=[main_output, auxiliary_output])"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(?, ?, 200)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "03MSGCP8VEx3",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "phase2_model.compile(loss={'LM_output': 'mse', 'POS_output': 'mse'},optimizer='rmsprop',metrics=['accuracy'])\n",
        "phase1_model.compile(loss={'LM_output': 'mse'},optimizer='rmsprop',metrics=['accuracy'])\n",
        "\n",
        "# model.compile(optimizer='rmsprop',\n",
        "#               loss={'main_output': 'binary_crossentropy', 'aux_output': 'binary_crossentropy'},\n",
        "#               loss_weights={'main_output': 1., 'aux_output': 0.2})\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9dlt5kwbVOqE",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "num_epochs=20"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yzaB12LGVdN5",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9b59637b-fafc-4294-aac3-78a4d520ea36",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1528813757361,
          "user_tz": -330,
          "elapsed": 2002,
          "user": {
            "displayName": "Murali Manohar",
            "photoUrl": "//lh4.googleusercontent.com/-FtcF8oOHMfk/AAAAAAAAAAI/AAAAAAAACRQ/64DBd_-9-UY/s50-c-k-no/photo.jpg",
            "userId": "117676050852919577098"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!mkdir data"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘data’: File exists\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "7HXzZfN2VZKE",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "phase1_checkpointer = ModelCheckpoint('data/phase1_model-{epoch:20}.hdf5', verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4GZfVlTWVfCA",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "d42cea2c-e2de-4994-b9b7-3a4f1630820e"
      },
      "cell_type": "code",
      "source": [
        "# phase1_model.fit_generator(phase1_train_data_generator.generate(phase=1), len(train_data)//(batch_size*num_steps), num_epochs, callbacks=[checkpointer])\n",
        "\n",
        "skip_steps=1\n",
        "phase1_model.fit_generator(phase1_train_data_generator.generate(phase=1), len(train_data)//(batch_size*skip_steps), num_epochs)\n",
        "\n",
        "\n",
        "# model.fit_generator(train_data_generator.generate(), 2000, num_epochs,\n",
        "    #                     validation_data=valid_data_generator.generate(),\n",
        "    #                     validation_steps=10)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "298/809 [==========>...................] - ETA: 10:38 - loss: 0.0020 - acc: 0.0604"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ghgVDWlFapQu",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "phase1_model.save(\"data/phase1_model.hdf5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gs5N-pU9VhN4",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "epiTDzNFbBy2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Store the weights of phase 1 model's layers"
      ]
    },
    {
      "metadata": {
        "id": "EQbsa1u9bCq2",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "phase1_model_weights = [(layer.name,layer.get_weights()) for layer in phase1_model.layers]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NYdOQiNAbFVA",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WSu_2BhmbHdV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# For every phase1 model layer that is present in phase2, we assign the stored \n",
        "\n",
        "# weights to the corresponding layers."
      ]
    },
    {
      "metadata": {
        "id": "vWujEQV-bHwG",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "for i in range(len(phase1_model_weights)):\n",
        "    if not phase2_model.get_layer(phase1_model_weights[i][0])==None:\n",
        "        print(phase1_model_weights[i][0],\" layer weights are assigned \")\n",
        "        phase2_model.get_layer(phase1_model_weights[i][0]).set_weights(phase1_model_weights[i][1])\n",
        "    else:\n",
        "        print(phase1_model_weights[i][0],\" layer with weights \",phase1_model_weights[i][1],\" are not copied\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Qc84edtNbJJ2",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WOZsIGxxbMYD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Run phase2_model . phase2_model.fit"
      ]
    },
    {
      "metadata": {
        "id": "hCblSmWIbMqn",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# phase2_model.fit_generator(phase2_train_data_generator.generate(phase=2), len(train_data)//(batch_size*num_steps), num_epochs, callbacks=[checkpointer])\n",
        "phase2_model.fit_generator(phase2_train_data_generator.generate(phase=2), len(train_data)//(batch_size), num_epochs)\n",
        "\n",
        "    # model.fit_generator(train_data_generator.generate(), 2000, num_epochs,\n",
        "    #                     validation_data=valid_data_generator.generate(),\n",
        "    #                     validation_steps=10)\n",
        "phase2_model.save(\"phase2_model.hdf5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mAuIRJLobOme",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}